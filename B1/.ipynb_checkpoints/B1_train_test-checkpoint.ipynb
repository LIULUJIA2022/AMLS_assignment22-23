{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f725fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Use early stopping to terminate training epochs through callbacks\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Import network libraries\n",
    "import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Set the GPU\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302c4d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define class for Task B1\n",
    "class CNN_B1:\n",
    "\t# Callback function to interrupt the overfitting model\n",
    "\tdef callback_func(self, B1_dir):\n",
    "\t\t# Seek a mininum for validation loss and display the stopped epochs using verbose and adding delays\n",
    "\t\tes = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=100)\n",
    "\n",
    "\t\t# Save best model using checkpoint\n",
    "\t\tmodel_path = os.path.join(B1_dir, 'VGGNet.h5')\n",
    "\t\tmcp = ModelCheckpoint(os.path.normcase(model_path), monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
    "\n",
    "\t\t# Define callback function in a list\n",
    "\t\tcallback_list = [es, mcp]\n",
    "\n",
    "\t\treturn callback_list, model_path\n",
    "\n",
    "\t# Training CNN network and save the model\n",
    "\tdef train(self, myDir, num_class, train_generator, valid_generator, eval_generator):\n",
    "\t\tcb_list, CNN_model_path = self.callback_func(myDir)\n",
    "\t\tepochs = 10\n",
    "\t\tmodel = Sequential()\n",
    "\n",
    "\t\tmodel.add(Conv2D(32, (3,3), padding=\"same\", input_shape=train_generator.image_shape))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(BatchNormalization())\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(3,3)))\n",
    "\t\tmodel.add(Dropout(0.25))\n",
    "\n",
    "\t\tmodel.add(Conv2D(64, (3,3), padding=\"same\"))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(BatchNormalization())\n",
    "\t\tmodel.add(Conv2D(64, (3,3), padding=\"same\"))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(BatchNormalization())\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\t\tmodel.add(Dropout(0.25))\n",
    "\n",
    "\t\tmodel.add(Conv2D(128, (3,3), padding=\"same\"))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(BatchNormalization())\n",
    "\t\tmodel.add(Conv2D(128, (3,3), padding=\"same\"))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(BatchNormalization())\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\t\tmodel.add(Dropout(0.25))\n",
    "\n",
    "\t\tmodel.add(Flatten())\n",
    "\t\tmodel.add(Dense(1024))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(BatchNormalization())\n",
    "\t\tmodel.add(Dropout(0.5))\n",
    "\n",
    "\t\tmodel.add(Dense(num_class))\n",
    "\t\tmodel.add(Activation(\"sigmoid\"))\n",
    "\t\tmodel.summary()\n",
    "\t\t# Compile the model using ADAM (Adaptive learning rate optimization)\n",
    "\t\tmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\t\t# Set steps per epoch for callback \n",
    "\t\tSTEP_SIZE_TRAIN = train_generator.samples//train_generator.batch_size\n",
    "\t\tSTEP_SIZE_VALID = valid_generator.samples//valid_generator.batch_size\n",
    "\n",
    "\t\thistory = model.fit_generator(generator=train_generator,\n",
    "\t\t\t\t\t\t\t\t\t\tsteps_per_epoch=STEP_SIZE_TRAIN,\n",
    "\t\t\t\t\t\t\t\t\t\tepochs=epochs,\n",
    "\t\t\t\t\t\t\t\t\t\tcallbacks=cb_list,\n",
    "\t\t\t\t\t\t\t\t\t\tvalidation_data=valid_generator,\n",
    "\t\t\t\t\t\t\t\t\t\tvalidation_steps=STEP_SIZE_VALID)\n",
    "\n",
    "\t\teval_model = model.evaluate_generator(generator=eval_generator, steps=STEP_SIZE_VALID, verbose=1)\n",
    "\t\tprint('Training '+ str(model.metrics_names[1]) + ': '  + str(eval_model[1]))\n",
    "\t\ttrain_acc = {'vggNet-muti': eval_model[1]}\n",
    "\n",
    "\t\t# plot training/validation loss/accuracy\n",
    "\t\tprint(history.history)\n",
    "\t\tplt.style.use(\"ggplot\")\n",
    "\t\tplt.figure()\n",
    "\t\tN = epochs\n",
    "\t\tplt.plot(np.arange(0,N), history.history[\"loss\"], label=\"train_loss\")\n",
    "\t\tplt.plot(np.arange(0,N), history.history[\"val_loss\"], label=\"val_loss\")\n",
    "\t\tplt.plot(np.arange(0,N), history.history[\"accuracy\"], label=\"train_acc\")\n",
    "\t\tplt.plot(np.arange(0,N), history.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "\n",
    "\t\tplt.title(\"Training Loss and Accuracy\")\n",
    "\t\tplt.xlabel(\"Epoch #\")\n",
    "\t\tplt.ylabel(\"Loss/Accuracy\")\n",
    "\t\tplt.legend(loc=\"upper right\")\n",
    "\n",
    "\t\t# save plot to disk\n",
    "\t\tplt.savefig(\"plot.png\")\n",
    "\t\treturn train_acc, CNN_model_path\n",
    "\n",
    "\n",
    "\tdef test(self, model_path, test_generator):\n",
    "\t\t# Fit the model to the test dataset by loading the model \n",
    "\t\tsaved_model = load_model(model_path)\n",
    "\n",
    "\t\t# Predict the face shape\n",
    "\t\tSTEP_SIZE_TEST = test_generator.samples//test_generator.batch_size\n",
    "\t\ttest_generator.reset()\n",
    "\t\tpred = saved_model.predict_generator(test_generator, steps=STEP_SIZE_TEST, verbose=1)\n",
    "\n",
    "\t\t# Determine the maximum activation value at the output layers for each sample\n",
    "\t\tpred_class = np.argmax(pred, axis=1)   # axis = 1 give max value along each row\n",
    "\n",
    "\t\t# True labels of test dataset\n",
    "\t\ttrue_class = test_generator.classes\n",
    "\n",
    "\t\t# Accuracy score\n",
    "\t\ttest_score = accuracy_score(true_class, pred_class)\n",
    "\n",
    "\t\ttest_acc = {'CNN-softmax': test_score}\n",
    "\n",
    "\t\treturn test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f44d061",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
